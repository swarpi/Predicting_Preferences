{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trung\\anaconda3\\envs\\torch_recommender\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json  # To handle JSON files\n",
    "import torch\n",
    "from datetime import date\n",
    "import time  # For tracking generation time\n",
    "\n",
    "# Ensure the current directory is in sys.path\n",
    "sys.path.append('./')  # Adjust the path if necessary\n",
    "\n",
    "# Import custom modules\n",
    "from data_loader import load_user_reviews\n",
    "from utils import (\n",
    "    normalize,\n",
    "    compute_similarity,\n",
    "    recall_at_k,\n",
    "    ndcg_at_k,\n",
    "    extract_latest_n_reviews,\n",
    "    extract_product_names_adapter,\n",
    "    extract_product_names_alpaca\n",
    ")\n",
    "from retrieval import initialize_chromadb, collect_results_per_product\n",
    "from model_pipeline import RecommenderModel  # Import the RecommenderModel class\n",
    "from config import (\n",
    "    PIPELINE_PARAMS,\n",
    "    USER_PROFILE_PROMPT,\n",
    "    PRELIMINARY_RECOMMENDATIONS_PROMPT,\n",
    "    ALPACA_LORA_PROMPTS_USER_PROFILE,\n",
    "    ALPACA_LORA_PROMPTS_CANDIDATE_ITEMS,\n",
    "    QLORA_PARAMS,\n",
    "    MODEL_PATH,\n",
    "    TOKENIZER_PATH,\n",
    "    get_model_path_user_profile_and_candidate_items,\n",
    "    get_tokenizer_path_user_profile_and_candidate_items\n",
    ")\n",
    "\n",
    "# Set the current date\n",
    "current_date = date.today()\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    num_runs=1,\n",
    "    with_product_description=False,\n",
    "    num_reviews=10,\n",
    "    sample_size=None,\n",
    "    dataset='beauty', \n",
    "    data_source='chatgpt_data'  # <--- NEW PARAM\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs the recommendation experiment with specified parameters.\n",
    "\n",
    "    Args:\n",
    "        num_runs (int): Number of times to run the experiment.\n",
    "        with_product_description (bool): Whether to include product descriptions in the preliminary recommendations.\n",
    "        num_reviews (int): Number of latest reviews to extract per user.\n",
    "        sample_size (int or None): Sample size for the model. If provided, adapter logic is used.\n",
    "        dataset (str): The dataset to use (\"beauty\" or \"video_games\").\n",
    "    \"\"\"\n",
    "    # Initialize the RecommenderModel with the adjusted paths\n",
    "    torch.cuda.empty_cache()\n",
    "    use_adapter = sample_size is not None  # determine if adapter logic should be used\n",
    "\n",
    "    # Initialize the RecommenderModel with new parameters\n",
    "    recommender_model = RecommenderModel(\n",
    "        sample_size=sample_size, \n",
    "        adapter=use_adapter,\n",
    "        dataset=dataset,           # <--- pass along\n",
    "        data_source=data_source    # <--- pass along\n",
    "    )\n",
    "\n",
    "    # Initialize ChromaDB following the logic from notebook#2\n",
    "    # We assume initialize_chromadb(dataset_name) returns the corresponding collection\n",
    "    collection = initialize_chromadb(dataset)\n",
    "\n",
    "    # Load product data depending on the dataset\n",
    "    if dataset == 'beauty':\n",
    "        train_file = 'new_data/new_train_val_output.json'\n",
    "        test_file = 'new_data/test_output.json'\n",
    "    elif dataset == 'video_games':\n",
    "        train_file = 'new_data/Video_Games.shortened_reduced_300_users.json'       # Adjust if a different file is used\n",
    "        test_file = 'new_data/Video_Games.test_reduced_300_users.json'             # Adjust if a different file is used\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset. Use 'beauty' or 'video_games'.\")\n",
    "\n",
    "    input_set = load_user_reviews(train_file)\n",
    "    input_set_test = load_user_reviews(test_file)\n",
    "    num_users = len(input_set)\n",
    "\n",
    "    # Experiment parameters\n",
    "    SIMILARITY_THRESHOLD = 100.0\n",
    "    K_VALUES = [1, 5, 10, 20]\n",
    "    MAX_TOTAL_RETRIES = 0\n",
    "    MAX_ITEM_RETRIES = 20 \n",
    "\n",
    "    # Initialize lists and counters\n",
    "    all_recalls, all_ndcgs = [], []\n",
    "    skipped_users = []\n",
    "    total_skips = 0  # Total number of users skipped\n",
    "    user_skip_counts = {}  # Dictionary to track skips per user\n",
    "\n",
    "    # Run the experiment for the specified number of runs\n",
    "    for run_num in range(num_runs):\n",
    "        print(f\"\\nStarting experiment run {run_num + 1}/{num_runs}...\")\n",
    "        results = []\n",
    "\n",
    "        # Define the result JSON file path - dataset is now included in the naming\n",
    "        description_flag = \"with_description\" if with_product_description else \"without_description\"\n",
    "        adapter_flag = f\"adapter_{use_adapter}\" if use_adapter else \"no_adapter\"\n",
    "        result_file_path = (\n",
    "            f\"results_{dataset}_\"\n",
    "            f\"{data_source}_\"\n",
    "            f\"{description_flag}_\"\n",
    "            f\"{adapter_flag}_\"\n",
    "            f\"reviews_{num_reviews}_\"\n",
    "            f\"sample_{sample_size}_\"\n",
    "            f\"{current_date}_\"\n",
    "            f\"run_{run_num + 1}_\"\n",
    "            f\"token_size_4096_\"\n",
    "            f\"with_full_reviews.json\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Loop over each user\n",
    "        for user_index in range(num_users):\n",
    "            print(f\"\\nProcessing user {user_index + 1}/{num_users}\")\n",
    "\n",
    "            # Start timing the user processing\n",
    "            start_time = time.time()\n",
    "\n",
    "            total_retries, success = 0, False\n",
    "            while not success and total_retries < MAX_TOTAL_RETRIES:\n",
    "                try:\n",
    "                    user_result = {'user_id': user_index + 1}\n",
    "                    example_user = [input_set[user_index]]\n",
    "                    latest_reviews = extract_latest_n_reviews(example_user, num_reviews)\n",
    "\n",
    "                    if not latest_reviews:\n",
    "                        print(f\"User {user_index + 1} skipped due to no latest reviews.\")\n",
    "                        skipped_users.append(user_index + 1)\n",
    "                        total_skips += 1\n",
    "                        user_skip_counts[user_index + 1] = total_retries\n",
    "                        break  # Exit top-level loop for this user\n",
    "\n",
    "                    # Track the number of reviews for this user\n",
    "                    num_user_reviews = len(latest_reviews)\n",
    "                    print(f\"Number of reviews for User {user_index + 1}: {num_user_reviews}\")\n",
    "                    user_result['num_reviews'] = num_user_reviews\n",
    "\n",
    "                    # Format review text\n",
    "                    review_text = [\n",
    "                        f\"Product: {review['product_name']}\\nRating: {review['rating']}\\nReview: {review['text']}\\n\"\n",
    "                        for review in latest_reviews\n",
    "                    ]\n",
    "                    print(f\"Review Text for User {user_index + 1}:\\n{review_text}\\n\")\n",
    "                    review_text_str = \"\\n\".join(review_text)\n",
    "\n",
    "                    # Generate user profile\n",
    "                    profile = recommender_model.create_user_profile(\n",
    "                        reviews=review_text_str,\n",
    "                        use_adapter=use_adapter\n",
    "                    )\n",
    "                    print(f\"Generated Profile for User {user_index + 1}:\\n{profile}\\n\")\n",
    "                    user_result['profile'] = profile\n",
    "\n",
    "                    # Generate preliminary recommendations (inner retry loop)\n",
    "                    retries_item = 0\n",
    "                    while retries_item < MAX_ITEM_RETRIES:\n",
    "                        try:\n",
    "                            preliminary_rec = recommender_model.create_preliminary_recommendations(\n",
    "                                user_profile=profile,\n",
    "                                use_adapter=use_adapter,\n",
    "                                product_descriptions=with_product_description\n",
    "                            )\n",
    "                            print(f\"Preliminary Recommendations for User {user_index + 1}:\\n{preliminary_rec}\\n\")\n",
    "                            user_result['preliminary_recommendations'] = preliminary_rec\n",
    "\n",
    "                            if use_adapter:\n",
    "                                product_names = extract_product_names_alpaca(preliminary_rec)\n",
    "                            else:\n",
    "                                product_names = extract_product_names_adapter(preliminary_rec)\n",
    "                            if not product_names:\n",
    "                                raise Exception(\"No product names extracted.\")\n",
    "\n",
    "                            print(f\"Extracted Product Names for User {user_index + 1}: {product_names}\\n\")\n",
    "                            user_result['extracted_products'] = product_names\n",
    "\n",
    "                            # If we reach here, item generation succeeded\n",
    "                            break\n",
    "\n",
    "                        except Exception as e:\n",
    "                            retries_item += 1\n",
    "                            print(f\"Error in item generation for user {user_index + 1}: {e}\")\n",
    "                            print(f\"Retrying item generation ({retries_item}/{MAX_ITEM_RETRIES})...\")\n",
    "\n",
    "                    else:\n",
    "                        # If we exhaust item retries without a 'break'\n",
    "                        # => Raise an exception to trigger a top-level retry\n",
    "                        raise Exception(\n",
    "                            f\"Max item retries ({MAX_ITEM_RETRIES}) reached for User {user_index + 1}. \"\n",
    "                            \"Reraising to top-level for another attempt.\"\n",
    "                        )\n",
    "\n",
    "                    # Collect final results per product\n",
    "                    user_history = [rev['parent_asin'] for rev in latest_reviews if 'parent_asin' in rev]\n",
    "                    final_results = collect_results_per_product(product_names, collection, user_history, max_products=20)\n",
    "                    if final_results == -1:\n",
    "                        print(f\"User {user_index + 1} skipped due to no recommendations.\")\n",
    "                        skipped_users.append(user_index + 1)\n",
    "                        total_skips += 1\n",
    "                        user_skip_counts[user_index + 1] = total_retries\n",
    "                        break\n",
    "\n",
    "                    # Get the test product from the test dataset\n",
    "                    example_user_test = [input_set_test[user_index]]\n",
    "                    test_review = extract_latest_n_reviews(example_user_test, 1)\n",
    "                    test_product = test_review[0]['parent_asin']\n",
    "                    user_result['test_product'] = test_product\n",
    "\n",
    "                    # Prepare recommended products list\n",
    "                    recommended_products = []\n",
    "                    for doc, distance, metadata in final_results:\n",
    "                        asin = metadata\n",
    "                        recommended_products.append({\n",
    "                            'asin': asin,\n",
    "                            'distance': distance\n",
    "                        })\n",
    "\n",
    "                    user_result['recommended_products'] = recommended_products\n",
    "\n",
    "                    # Evaluate recommendations\n",
    "                    normalized_test_product = normalize(test_product)\n",
    "                    normalized_ranked_products = [normalize(prod['asin']) for prod in recommended_products]\n",
    "                    similarity_scores = []\n",
    "                    matches = []\n",
    "                    for rec_product in normalized_ranked_products:\n",
    "                        sim_score = compute_similarity(rec_product, normalized_test_product)\n",
    "                        similarity_scores.append(sim_score)\n",
    "                        matches.append(sim_score >= SIMILARITY_THRESHOLD)\n",
    "\n",
    "                    # Add evaluation results to user_result\n",
    "                    for idx, (prod, score, match) in enumerate(zip(recommended_products, similarity_scores, matches)):\n",
    "                        prod['similarity_score'] = score\n",
    "                        prod['match'] = match\n",
    "\n",
    "                    print(\"\\nSimilarity Scores and Matches:\")\n",
    "                    for idx, (prod, score, match) in enumerate(zip(recommended_products, similarity_scores, matches), 1):\n",
    "                        print(f\"{idx}. ASIN: {prod['asin']}\")\n",
    "                        print(f\"   Similarity Score: {score:.2f}%\")\n",
    "                        print(f\"   Match: {'Yes' if match else 'No'}\")\n",
    "\n",
    "                    # Collect Recall@K and NDCG@K for this user\n",
    "                    user_recalls = {}\n",
    "                    user_ndcgs = {}\n",
    "                    for k in K_VALUES:\n",
    "                        recall_val = recall_at_k(matches, k)\n",
    "                        ndcg_val = ndcg_at_k(matches, k)\n",
    "                        user_recalls[f'Recall@{k}'] = recall_val\n",
    "                        user_ndcgs[f'NDCG@{k}'] = ndcg_val\n",
    "                        all_recalls.append((k, recall_val))\n",
    "                        all_ndcgs.append((k, ndcg_val))\n",
    "\n",
    "                    user_result['evaluation'] = {\n",
    "                        'recalls': user_recalls,\n",
    "                        'ndcgs': user_ndcgs\n",
    "                    }\n",
    "\n",
    "                    # Add retries information to user_result\n",
    "                    user_result['total_retries'] = total_retries\n",
    "                    user_result['item_retries'] = retries_item\n",
    "\n",
    "                    # Stop timing\n",
    "                    end_time = time.time()\n",
    "                    generation_time = end_time - start_time\n",
    "                    print(f\"Time taken for user {user_index + 1}: {generation_time:.2f} seconds\")\n",
    "                    user_result['generation_time'] = generation_time\n",
    "\n",
    "                    # Append user_result to results\n",
    "                    results.append(user_result)\n",
    "\n",
    "                    # Mark the user as successfully processed\n",
    "                    success = True\n",
    "\n",
    "                except Exception as e:\n",
    "                    total_retries += 1\n",
    "                    print(f\"Error processing user {user_index + 1}: {e}\")\n",
    "                    if total_retries >= MAX_TOTAL_RETRIES:\n",
    "                        # If we've already retried top-level logic 3 times, skip user\n",
    "                        print(f\"User {user_index + 1} skipped after {MAX_TOTAL_RETRIES} top-level retries.\")\n",
    "                        skipped_users.append(user_index + 1)\n",
    "                        total_skips += 1\n",
    "                        user_skip_counts[user_index + 1] = total_retries\n",
    "\n",
    "                        end_time = time.time()\n",
    "                        generation_time = end_time - start_time\n",
    "                        print(f\"Time taken for user {user_index + 1}: {generation_time:.2f} seconds\")\n",
    "\n",
    "                    else:\n",
    "                        print(\n",
    "                            f\"Retrying user processing (Profile + Item Generation) \"\n",
    "                            f\"({total_retries}/{MAX_TOTAL_RETRIES})...\"\n",
    "                        )\n",
    "\n",
    "\n",
    "        # Calculate overall metrics for each K\n",
    "        overall_metrics = {}\n",
    "        for k in K_VALUES:\n",
    "            recalls_at_k = [rec for k_val, rec in all_recalls if k_val == k]\n",
    "            ndcgs_at_k = [ndcg for k_val, ndcg in all_ndcgs if k_val == k]\n",
    "            mean_recall = np.mean(recalls_at_k) if recalls_at_k else 0.0\n",
    "            mean_ndcg = np.mean(ndcgs_at_k) if ndcgs_at_k else 0.0\n",
    "            overall_metrics[f'Recall@{k}'] = mean_recall\n",
    "            overall_metrics[f'NDCG@{k}'] = mean_ndcg\n",
    "\n",
    "        # Prepare the final JSON data\n",
    "        json_data = {\n",
    "            'experiment_info': {\n",
    "                'sample_size': sample_size,\n",
    "                'num_run': run_num + 1,\n",
    "                'adapter': use_adapter,\n",
    "                'with_product_description': with_product_description,\n",
    "                'num_reviews': num_reviews,\n",
    "                'date': str(current_date),\n",
    "                'dataset': dataset,\n",
    "                'data_source': data_source,   # <--- store in experiment info\n",
    "            },\n",
    "            'results': results,\n",
    "            'overall_metrics': overall_metrics,\n",
    "            'skipped_users': skipped_users,\n",
    "            'total_skips': total_skips,\n",
    "            'user_skip_counts': user_skip_counts\n",
    "        }\n",
    "\n",
    "        # Write the JSON data to the file\n",
    "        with open(result_file_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "        print(f\"Experiment run {run_num + 1} completed. Results saved to {result_file_path}.\")\n",
    "        print(f\"Total users skipped in this run: {total_skips}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment( #TODO need to run\n",
    "    num_runs=3,\n",
    "    with_product_description=False,\n",
    "    num_reviews=100,\n",
    "    dataset= \"video_games\",\n",
    ")\n",
    "run_experiment( #TODO need to run\n",
    "    num_runs=3,\n",
    "    with_product_description=False,\n",
    "    num_reviews=100,\n",
    "    dataset= \"beauty\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
