{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine test and val set with train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def combine_data(train_val_data, test_data):\n",
    "    # Create a dictionary from train_val_data keyed by user_id for quick look-up\n",
    "    train_val_dict = { user[\"user_id\"]: user for user in train_val_data }\n",
    "\n",
    "    # Iterate over test_data users\n",
    "    for test_user in test_data:\n",
    "        user_id = test_user[\"user_id\"]\n",
    "        test_reviews = test_user[\"reviews\"]\n",
    "\n",
    "        if user_id in train_val_dict:\n",
    "            # If user exists in train_val, append the new reviews\n",
    "            train_val_dict[user_id][\"reviews\"].extend(test_reviews)\n",
    "        else:\n",
    "            # If user does not exist in train_val, add this new user entry\n",
    "            train_val_dict[user_id] = {\n",
    "                \"user_id\": user_id,\n",
    "                \"reviews\": test_reviews\n",
    "            }\n",
    "\n",
    "    # Convert dictionary back to list \n",
    "    combined_data = list(train_val_dict.values())\n",
    "    return combined_data\n",
    "\n",
    "# File paths using data folder structure\n",
    "dataset_name = \"Beauty\"  # or \"video_games\"\n",
    "train_file = f\"data/{dataset_name}_train_output.json\"\n",
    "test_file = f\"data/{dataset_name}_test_output.json\" \n",
    "val_file = f\"data/{dataset_name}_val_output.json\"\n",
    "combined_file = f\"data/{dataset_name}_combined_test_val_train.json\"\n",
    "\n",
    "# Read train and validation data\n",
    "with open(train_file, \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(val_file, \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "# Combine train and val first\n",
    "train_val_data = combine_data(train_data, val_data)\n",
    "\n",
    "# Read and combine with test data\n",
    "with open(test_file, \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "combined = combine_data(train_val_data, test_data)\n",
    "\n",
    "# Write combined data to output file\n",
    "with open(combined_file, \"w\") as f:\n",
    "    json.dump(combined, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cpu\n",
      "INFO:__main__:Loading reduced file: /Users/trung/Uni/MasterThesis/code/pred_pref/data/Beauty_combined.json\n",
      "INFO:__main__:Number of unique items in reduced data: 356\n",
      "INFO:__main__:Loading model and tokenizer from hyp1231/blair-roberta-large\n",
      "INFO:__main__:Model loaded and set to evaluation mode.\n",
      "INFO:__main__:Reading meta file: /Users/trung/Uni/MasterThesis/code/pred_pref/data/meta_All_Beauty.jsonl\n",
      "ERROR:__main__:File not found: /Users/trung/Uni/MasterThesis/code/pred_pref/data/meta_All_Beauty.jsonl. Error: [Errno 2] No such file or directory: '/Users/trung/Uni/MasterThesis/code/pred_pref/data/meta_All_Beauty.jsonl'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/trung/Uni/MasterThesis/code/pred_pref/data/meta_All_Beauty.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m selected_asins \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     80\u001b[0m selected_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(META_FILE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m tqdm(f, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading meta file\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     83\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/trung/Uni/MasterThesis/code/pred_pref/data/meta_All_Beauty.jsonl'"
     ]
    }
   ],
   "source": [
    "from config import DATABASES, EMBEDDING_MODEL_CONFIG\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import chromadb\n",
    "import uuid\n",
    "\n",
    "# ---------------------- Configuration ----------------------\n",
    "dataset_name = \"beauty\"  # or \"video_games\"\n",
    "db_config = DATABASES[dataset_name]\n",
    "REDUCED_FILE = db_config['data_paths']['reduced_file']\n",
    "META_FILE = db_config['data_paths']['meta_file']\n",
    "CHROMA_DB_PATH = db_config['db_path']\n",
    "CHROMA_COLLECTION_NAME = db_config['collection_name']\n",
    "BATCH_SIZE = EMBEDDING_MODEL_CONFIG['batch_size']\n",
    "MODEL_NAME = EMBEDDING_MODEL_CONFIG['name']\n",
    "\n",
    "# ---------------------- Logging ----------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ---------------------- Device Setup ----------------------\n",
    "device = EMBEDDING_MODEL_CONFIG['device']\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------------- Load Reduced Data ----------------------\n",
    "try:\n",
    "    logger.info(f\"Loading reduced file: {REDUCED_FILE}\")\n",
    "    with open(REDUCED_FILE, 'r', encoding='utf-8') as f:\n",
    "        reduced_data = json.load(f)\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"File not found: {REDUCED_FILE}. Error: {e}\")\n",
    "    raise\n",
    "except json.JSONDecodeError as e:\n",
    "    logger.error(f\"Error decoding JSON in file: {REDUCED_FILE}. Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Extract all unique parent_asin from reduced_data\n",
    "unique_items = set()\n",
    "try:\n",
    "    for user_entry in reduced_data:\n",
    "        for review in user_entry.get(\"reviews\", []):\n",
    "            unique_items.add(review.get(\"parent_asin\"))\n",
    "    logger.info(f\"Number of unique items in reduced data: {len(unique_items)}\")\n",
    "except KeyError as e:\n",
    "    logger.error(f\"Unexpected data format in reduced_data: {e}\")\n",
    "    raise\n",
    "\n",
    "# ---------------------- Initialize Model ----------------------\n",
    "try:\n",
    "    logger.info(f\"Loading model and tokenizer from {MODEL_NAME}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "    model.eval()\n",
    "    logger.info(\"Model loaded and set to evaluation mode.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading model: {MODEL_NAME}. Error: {e}\")\n",
    "    raise\n",
    "\n",
    "def embed_texts(texts):\n",
    "    \"\"\"Embed a list of texts using the model and return the embeddings.\"\"\"\n",
    "    try:\n",
    "        inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, return_dict=True)\n",
    "            embeddings = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "            embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)  # Normalize\n",
    "        return embeddings.cpu().numpy().tolist()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during text embedding: {e}\")\n",
    "        raise\n",
    "\n",
    "# ---------------------- Read Meta File and Select Items ----------------------\n",
    "try:\n",
    "    logger.info(f\"Reading meta file: {META_FILE}\")\n",
    "    selected_asins = []\n",
    "    selected_texts = []\n",
    "    with open(META_FILE, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"Reading meta file\"):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                logger.warning(f\"Invalid JSON line skipped: {line}\")\n",
    "                continue\n",
    "\n",
    "            parent_asin = data.get(\"parent_asin\", \"\")\n",
    "            if parent_asin in unique_items:\n",
    "                title = data.get(\"title\", \"\")\n",
    "                description_field = data.get(\"description\", [])\n",
    "                description = \" \".join(description_field) if isinstance(description_field, list) else str(description_field)\n",
    "\n",
    "                details_field = data.get(\"details\", {})\n",
    "                details_str = \" \".join([f\"{k}: {v}\" for k, v in details_field.items()]) if isinstance(details_field, dict) else str(details_field)\n",
    "\n",
    "                combined_text = \". \".join(filter(None, [title, description, details_str]))\n",
    "                selected_asins.append(parent_asin)\n",
    "                selected_texts.append(combined_text)\n",
    "\n",
    "    logger.info(f\"Number of matched items in meta: {len(selected_asins)}\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"File not found: {META_FILE}. Error: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"Unexpected error reading meta file: {META_FILE}. Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# ---------------------- Initialize ChromaDB ----------------------\n",
    "try:\n",
    "    logger.info(\"Initializing ChromaDB client.\")\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "\n",
    "    # Use get_or_create to avoid UniqueConstraintError\n",
    "    collection_chroma = chroma_client.create_collection(\n",
    "        name=CHROMA_COLLECTION_NAME,\n",
    "        get_or_create=True  # Ensures collection is retrieved if it already exists\n",
    "    )\n",
    "\n",
    "    logger.info(f\"ChromaDB collection '{CHROMA_COLLECTION_NAME}' initialized.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing ChromaDB collection: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# ---------------------- Embedding and Storing Directly in ChromaDB ----------------------\n",
    "if not selected_texts:\n",
    "    logger.warning(\"No texts to embed. Exiting.\")\n",
    "else:\n",
    "    try:\n",
    "        total_texts = len(selected_texts)\n",
    "        logger.info(f\"Embedding {total_texts} texts in batches of {BATCH_SIZE} and adding directly to ChromaDB...\")\n",
    "\n",
    "        for i in range(0, total_texts, BATCH_SIZE):\n",
    "            batch_texts = selected_texts[i:i + BATCH_SIZE]\n",
    "            batch_asins = selected_asins[i:i + BATCH_SIZE]\n",
    "            embeddings_list = embed_texts(batch_texts)\n",
    "\n",
    "            ids = [str(uuid.uuid4()) for _ in batch_texts]\n",
    "            metadatas = [{\"parent_asin\": asin} for asin in batch_asins]\n",
    "\n",
    "            try:\n",
    "                collection_chroma.add(\n",
    "                    ids=ids,\n",
    "                    documents=batch_texts,\n",
    "                    embeddings=embeddings_list,\n",
    "                    metadatas=metadatas\n",
    "                )\n",
    "                logger.info(f\"Inserted batch {(i // BATCH_SIZE) + 1} into ChromaDB.\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error inserting documents into ChromaDB: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during embedding or storing process: {e}\")\n",
    "    logger.info(\"Completed embedding and storing items directly into ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ChromaDB_Test.ipynb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import dependencies\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mretrieval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize_chromadb, collect_results_per_product  \u001b[38;5;66;03m# From your updated retrieval.py\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DATABASES  \u001b[38;5;66;03m# Import the configurations\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize logging\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/MasterThesis/code/pred_pref/retrieval.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# ChromaDB_Test.ipynb\n",
    "\n",
    "# Import dependencies\n",
    "import logging\n",
    "from retrieval import initialize_chromadb, collect_results_per_product  # From your updated retrieval.py\n",
    "from config import DATABASES  # Import the configurations\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Test parameters\n",
    "test_product_names = [\"The Last of Us\", \"Call of Duty\", \"Minecraft\"]  # Example product names for video games\n",
    "user_history = [\"existing_asin_1\", \"existing_asin_2\"]  # Example user history to avoid duplicates\n",
    "max_products = 20  # Limit for the results\n",
    "\n",
    "# Step 1: Test Video Games Collection\n",
    "print(\"=== Testing Video Games Collection ===\")\n",
    "\n",
    "try:\n",
    "    # Initialize Video Games collection\n",
    "    video_games_collection = initialize_chromadb(\"video_games\")\n",
    "    \n",
    "    # Run the collect_results_per_product function\n",
    "    video_games_results = collect_results_per_product(\n",
    "        product_names=test_product_names,\n",
    "        collection=video_games_collection,\n",
    "        user_history=user_history,\n",
    "        max_products=max_products\n",
    "    )\n",
    "    \n",
    "    # Output the results\n",
    "    print(\"\\nVideo Games Results:\")\n",
    "    if video_games_results == -1:\n",
    "        print(\"No results found for Video Games collection.\")\n",
    "    else:\n",
    "        for document, distance, metadata in video_games_results:\n",
    "            print(f\"Document: {document}\")\n",
    "            print(f\"Distance: {distance}\")\n",
    "            print(f\"Metadata: {metadata}\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Video Games collection test: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl (436 kB)\n",
      "Installing collected packages: safetensors, transformers\n",
      "Successfully installed safetensors-0.5.3 transformers-4.49.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cuda\n",
      "INFO:__main__:Processing dataset: video_games\n",
      "INFO:__main__:Loading reduced file: new_data/Video_Games.reduced_300_users.json\n",
      "INFO:__main__:Number of unique items in reduced data: 2516\n",
      "INFO:__main__:Loading model and tokenizer from sentence-transformers/all-mpnet-base-v2\n",
      "INFO:__main__:Model loaded and set to evaluation mode.\n",
      "INFO:__main__:Reading meta file: new_data/meta_Video_Games.jsonl\n",
      "Reading meta file: 137269it [00:01, 70181.43it/s]\n",
      "INFO:__main__:Number of matched items in meta: 2516\n",
      "INFO:__main__:Initializing ChromaDB client.\n",
      "INFO:__main__:ChromaDB collection 'video_games_product_embeddings_mpnet' initialized.\n",
      "INFO:__main__:Embedding 2516 texts in batches of 32 and adding directly to ChromaDB...\n",
      "INFO:__main__:Inserted batch 1 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 2 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 3 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 4 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 5 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 6 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 7 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 8 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 9 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 10 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 11 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 12 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 13 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 14 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 15 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 16 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 17 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 18 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 19 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 20 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 21 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 22 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 23 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 24 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 25 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 26 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 27 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 28 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 29 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 30 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 31 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 32 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 33 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 34 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 35 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 36 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 37 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 38 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 39 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 40 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 41 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 42 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 43 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 44 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 45 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 46 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 47 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 48 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 49 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 50 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 51 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 52 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 53 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 54 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 55 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 56 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 57 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 58 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 59 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 60 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 61 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 62 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 63 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 64 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 65 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 66 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 67 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 68 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 69 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 70 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 71 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 72 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 73 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 74 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 75 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 76 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 77 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 78 into ChromaDB.\n",
      "INFO:__main__:Inserted batch 79 into ChromaDB.\n",
      "INFO:__main__:Completed embedding and storing items directly into ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import chromadb\n",
    "import uuid\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to Python path\n",
    "sys.path.append(\"D:/Master_Thesis/final_pipeline\")\n",
    "from config import DATASET_CONFIGS_MPNET\n",
    "\n",
    "# ---------------------- Configuration ----------------------\n",
    "\n",
    "# Dataset selection\n",
    "dataset = \"video_games\"  # Change to \"video_games\" as needed\n",
    "\n",
    "# Dataset-specific file paths\n",
    "DATA_PATHS = {\n",
    "    'beauty': {\n",
    "        'reduced_file': \"new_data/beauty_combined_output.json\",\n",
    "        'meta_file': \"new_data/meta_All_Beauty.jsonl\",\n",
    "    },\n",
    "    'video_games': {\n",
    "        'reduced_file': \"new_data/Video_Games.reduced_300_users.json\",\n",
    "        'meta_file': \"new_data/meta_Video_Games.jsonl\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get configuration from config file\n",
    "db_config = DATASET_CONFIGS_MPNET[dataset]\n",
    "REDUCED_FILE = DATA_PATHS[dataset]['reduced_file']\n",
    "META_FILE = DATA_PATHS[dataset]['meta_file']\n",
    "CHROMA_DB_PATH = db_config['db_path']\n",
    "CHROMA_COLLECTION_NAME = db_config['collection_name']\n",
    "\n",
    "# Model configuration\n",
    "BATCH_SIZE = 32\n",
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "# ---------------------- Logging ----------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ---------------------- Device Setup ----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "logger.info(f\"Processing dataset: {dataset}\")\n",
    "\n",
    "# ---------------------- Load Reduced Data ----------------------\n",
    "try:\n",
    "    logger.info(f\"Loading reduced file: {REDUCED_FILE}\")\n",
    "    with open(REDUCED_FILE, 'r', encoding='utf-8') as f:\n",
    "        reduced_data = json.load(f)\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"File not found: {REDUCED_FILE}. Error: {e}\")\n",
    "    raise\n",
    "except json.JSONDecodeError as e:\n",
    "    logger.error(f\"Error decoding JSON in file: {REDUCED_FILE}. Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Extract all unique parent_asin from reduced_data\n",
    "unique_items = set()\n",
    "try:\n",
    "    for user_entry in reduced_data:\n",
    "        for review in user_entry.get(\"reviews\", []):\n",
    "            unique_items.add(review.get(\"parent_asin\"))\n",
    "    logger.info(f\"Number of unique items in reduced data: {len(unique_items)}\")\n",
    "except KeyError as e:\n",
    "    logger.error(f\"Unexpected data format in reduced_data: {e}\")\n",
    "    raise\n",
    "\n",
    "# ---------------------- Initialize Model ----------------------\n",
    "try:\n",
    "    logger.info(f\"Loading model and tokenizer from {MODEL_NAME}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "    model.eval()\n",
    "    logger.info(\"Model loaded and set to evaluation mode.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading model: {MODEL_NAME}. Error: {e}\")\n",
    "    raise\n",
    "\n",
    "def embed_texts(texts):\n",
    "    \"\"\"Embed a list of texts using the model and return the embeddings.\"\"\"\n",
    "    try:\n",
    "        inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, return_dict=True)\n",
    "            embeddings = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "            embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)  # Normalize\n",
    "        return embeddings.cpu().numpy().tolist()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during text embedding: {e}\")\n",
    "        raise\n",
    "\n",
    "# ---------------------- Read Meta File and Select Items ----------------------\n",
    "try:\n",
    "    logger.info(f\"Reading meta file: {META_FILE}\")\n",
    "    selected_asins = []\n",
    "    selected_texts = []\n",
    "    with open(META_FILE, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"Reading meta file\"):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                logger.warning(f\"Invalid JSON line skipped: {line}\")\n",
    "                continue\n",
    "\n",
    "            parent_asin = data.get(\"parent_asin\", \"\")\n",
    "            if parent_asin in unique_items:\n",
    "                title = data.get(\"title\", \"\")\n",
    "                description_field = data.get(\"description\", [])\n",
    "                description = \" \".join(description_field) if isinstance(description_field, list) else str(description_field)\n",
    "\n",
    "                details_field = data.get(\"details\", {})\n",
    "                details_str = \" \".join([f\"{k}: {v}\" for k, v in details_field.items()]) if isinstance(details_field, dict) else str(details_field)\n",
    "\n",
    "                combined_text = \". \".join(filter(None, [title, description, details_str]))\n",
    "                selected_asins.append(parent_asin)\n",
    "                selected_texts.append(combined_text)\n",
    "\n",
    "    logger.info(f\"Number of matched items in meta: {len(selected_asins)}\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"File not found: {META_FILE}. Error: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"Unexpected error reading meta file: {META_FILE}. Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# ---------------------- Initialize ChromaDB ----------------------\n",
    "try:\n",
    "    logger.info(\"Initializing ChromaDB client.\")\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "\n",
    "    collection_chroma = chroma_client.create_collection(\n",
    "        name=CHROMA_COLLECTION_NAME,\n",
    "        get_or_create=True\n",
    "    )\n",
    "\n",
    "    logger.info(f\"ChromaDB collection '{CHROMA_COLLECTION_NAME}' initialized.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing ChromaDB collection: {e}\")\n",
    "    raise\n",
    "\n",
    "# ---------------------- Embedding and Storing Directly in ChromaDB ----------------------\n",
    "if not selected_texts:\n",
    "    logger.warning(\"No texts to embed. Exiting.\")\n",
    "else:\n",
    "    try:\n",
    "        total_texts = len(selected_texts)\n",
    "        logger.info(f\"Embedding {total_texts} texts in batches of {BATCH_SIZE} and adding directly to ChromaDB...\")\n",
    "\n",
    "        for i in range(0, total_texts, BATCH_SIZE):\n",
    "            batch_texts = selected_texts[i:i + BATCH_SIZE]\n",
    "            batch_asins = selected_asins[i:i + BATCH_SIZE]\n",
    "\n",
    "            embeddings_list = embed_texts(batch_texts)\n",
    "\n",
    "            ids = [str(uuid.uuid4()) for _ in batch_texts]\n",
    "            metadatas = [{\"parent_asin\": asin} for asin in batch_asins]\n",
    "\n",
    "            try:\n",
    "                collection_chroma.add(\n",
    "                    ids=ids,\n",
    "                    documents=batch_texts,\n",
    "                    embeddings=embeddings_list,\n",
    "                    metadatas=metadatas\n",
    "                )\n",
    "                logger.info(f\"Inserted batch {(i // BATCH_SIZE) + 1} into ChromaDB.\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error inserting documents into ChromaDB: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during embedding or storing process: {e}\")\n",
    "    logger.info(\"Completed embedding and storing items directly into ChromaDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ChromaDB Collections with MPNet Embeddings and Queries\n",
      "\n",
      "==================== Testing VIDEO_GAMES Collection ====================\n",
      "\n",
      "Total items in collection: 2516\n",
      "\n",
      "Sample of stored items:\n",
      "\n",
      "Item 1:\n",
      "ID: f30dc03b-e8cd-4a07-adc2-5a1e058d6be5\n",
      "Metadata: {'parent_asin': 'B00Z9TLVK0'}\n",
      "Document preview: NBA 2K17 - Early Tip Off Edition - PlayStation 4. Following the record-breaking launch of NBA 2K16, the NBA 2K franchise continues to stake its claim ...\n",
      "\n",
      "Item 2:\n",
      "ID: d8745da1-6b86-40ed-85cc-043cfb6f4df5\n",
      "Metadata: {'parent_asin': 'B00BJH85SW'}\n",
      "Document preview: Turbo: Super Stunt Squad - Nintendo 3DS. Product Description Turbo: Super Stunt Squad is a high-velocity action racing game featuring the super-charge...\n",
      "\n",
      "Performing test queries for video_games:\n",
      "\n",
      "Query: 'action adventure game with great story'\n",
      "\n",
      "Top 3 matches:\n",
      "\n",
      "Match 1:\n",
      "Distance: 1.1474\n",
      "Metadata: {'parent_asin': 'B0812PG2ZH'}\n",
      "Document preview: New Super Lucky's Tale - Nintendo Switch. Jump, burrow, and tail swipe your way to victory in this love letter to classic 3D platformers!Join Lucky on...\n",
      "\n",
      "Match 2:\n",
      "Distance: 1.1558\n",
      "Metadata: {'parent_asin': 'B001EYUNVC'}\n",
      "Document preview: The Legend of Zelda: Twilight Princess. Product description The Legend Of Zelda: Twilight Princess brings you back tot he land of Hyrule, as you uncov...\n",
      "\n",
      "Match 3:\n",
      "Distance: 1.1630\n",
      "Metadata: {'parent_asin': 'B0028556EU'}\n",
      "Document preview: Amazing Adventures: Around The World - PC. Pieces of an ancient stone tablet have started turning up around the globe and the Museum needs your help t...\n",
      "\n",
      "Query: 'multiplayer strategy game'\n",
      "\n",
      "Top 3 matches:\n",
      "\n",
      "Match 1:\n",
      "Distance: 1.2445\n",
      "Metadata: {'parent_asin': 'B003JVCA9Q'}\n",
      "Document preview: Call of Duty: Black Ops - Playstation 3. Product Description The newest installment in the biggest action series of all time and the follow-up to last...\n",
      "\n",
      "Match 2:\n",
      "Distance: 1.2587\n",
      "Metadata: {'parent_asin': 'B003JVKHEQ'}\n",
      "Document preview: Call of Duty: Black Ops - Xbox 360. Product Description The newest installment in the biggest action series of all time and the follow up to last year...\n",
      "\n",
      "Match 3:\n",
      "Distance: 1.2601\n",
      "Metadata: {'parent_asin': 'B003R7JXMO'}\n",
      "Document preview: Homefront - Xbox 360. Product Description The year is 2027. The world as we know it is unraveling after fifteen years of economic meltdown and widespr...\n",
      "\n",
      "Query: 'role playing game with open world'\n",
      "\n",
      "Top 3 matches:\n",
      "\n",
      "Match 1:\n",
      "Distance: 1.2370\n",
      "Metadata: {'parent_asin': 'B007W5P8TE'}\n",
      "Document preview: The Secret World - PC. Product Description Dark days are coming. All the myths, legends and conspiracies of the world are true. Three secret societies...\n",
      "\n",
      "Match 2:\n",
      "Distance: 1.3032\n",
      "Metadata: {'parent_asin': 'B0051D8P26'}\n",
      "Document preview: Disney Universe - Xbox 360. Disney Universe is an off-the-wall non-stop action adventure where Disney worlds and characters mix up for the first time....\n",
      "\n",
      "Match 3:\n",
      "Distance: 1.3085\n",
      "Metadata: {'parent_asin': 'B00ZQB28XK'}\n",
      "Document preview: No Man's Sky - PlayStation 4. Inspired by classic science-fiction and its overwhelming sense of adventure and imagination, Hello Games presents a game...\n",
      "\n",
      "==================== Testing BEAUTY Collection ====================\n",
      "\n",
      "Total items in collection: 356\n",
      "\n",
      "Sample of stored items:\n",
      "\n",
      "Item 1:\n",
      "ID: 01c5d76f-62a4-4833-a3cf-f9178178ef52\n",
      "Metadata: {'parent_asin': 'B08LYT4Q2X'}\n",
      "Document preview: Organic Sweet Almond Oil and Fractionated Coconut Oil Bundle for Hair and Skin, 100% Pure and Natural, Hexane-Free, Moisturizing, For Healthy Skin, Si...\n",
      "\n",
      "Item 2:\n",
      "ID: 1e192b70-bdec-43cb-9ffd-a43a1fef8ed7\n",
      "Metadata: {'parent_asin': 'B089CSF11Y'}\n",
      "Document preview: Empty Brown Glass Spray Bottles2-Pack, Refillable 16 oz Containers for Essential Oils, Cleaning Products, Aromatherapy, Misting Plants, or Cooking - R...\n",
      "\n",
      "Performing test queries for beauty:\n",
      "\n",
      "Query: 'moisturizing face cream for dry skin'\n",
      "\n",
      "Top 3 matches:\n",
      "\n",
      "Match 1:\n",
      "Distance: 1.1151\n",
      "Metadata: {'parent_asin': 'B07NPCT6L5'}\n",
      "Document preview: Dr. Au Anti-Aging Face Oil Retinol Serum by Au Natural Skinfood - Promotes Youthful, Glowing Skin | Collagen Boosting Wrinkle Repair | No Oily Residue...\n",
      "\n",
      "Match 2:\n",
      "Distance: 1.1293\n",
      "Metadata: {'parent_asin': 'B08C71WBLC'}\n",
      "Document preview: Moisturizing Facial Emulsion for Restoring Hydrating Smoothing Skin from Manilla Natural Skincare. Brand: Manilla Natural Skincare Scent: Coconut Item...\n",
      "\n",
      "Match 3:\n",
      "Distance: 1.1421\n",
      "Metadata: {'parent_asin': 'B07DFNPVSF'}\n",
      "Document preview: Dr. Denese SkinScience Essential Lipid Anti Aging Power Infusion Dry Oil - Skin Nutrients 97% Organic 100% Natural - Rejuvinating Blend with Amaranth ...\n",
      "\n",
      "Query: 'natural organic shampoo'\n",
      "\n",
      "Top 3 matches:\n",
      "\n",
      "Match 1:\n",
      "Distance: 0.8764\n",
      "Metadata: {'parent_asin': 'B085J24382'}\n",
      "Document preview: Mr. Pristine Organic Beard Shampoo with Natural Essential Oils for Moisturizing Skin & Hair, 8.5 oz.. Brand: Mr. Pristine Item Form: Liquid Hair Type:...\n",
      "\n",
      "Match 2:\n",
      "Distance: 1.0208\n",
      "Metadata: {'parent_asin': 'B085J354CL'}\n",
      "Document preview: Mr. Pristine Organic Beard Conditioner to Grow, Thicken, Moisturize and Protect Your Beard, 8.5 oz.. Brand: Mr. Pristine Material Feature: Natural Hai...\n",
      "\n",
      "Match 3:\n",
      "Distance: 1.0417\n",
      "Metadata: {'parent_asin': 'B08QKXY1KN'}\n",
      "Document preview: Purple Shampoo and Conditioner Set - Sulfate Free Salon Grade (2 x 16.9 fl oz) - Hydrating Toner - Shimmer Correction for Platinum Blonde, Silver, Lig...\n",
      "\n",
      "Query: 'anti-aging serum with vitamin C'\n",
      "\n",
      "Top 3 matches:\n",
      "\n",
      "Match 1:\n",
      "Distance: 0.9186\n",
      "Metadata: {'parent_asin': 'B08BZ1RHPS'}\n",
      "Document preview: MD Complete Bright & Healthy Vitamin C+ Vitalizing Face Serum| with Vitamin C, Vitamin E and Herbal Extracts | Potent Antioxidant Protection, Nourishe...\n",
      "\n",
      "Match 2:\n",
      "Distance: 0.9494\n",
      "Metadata: {'parent_asin': 'B07WNBZQGT'}\n",
      "Document preview: SERUM By MERLOT - RESVERATROL - NATURAL ANTI-AGING - DAMAGE CORRECTOR - BOOST COLLAGEN - 1 FL OZ. - DARK CIRCLE CORRECTOR -. Product Benefits: Anti-Ag...\n",
      "\n",
      "Match 3:\n",
      "Distance: 1.0298\n",
      "Metadata: {'parent_asin': 'B07NPCT6L5'}\n",
      "Document preview: Dr. Au Anti-Aging Face Oil Retinol Serum by Au Natural Skinfood - Promotes Youthful, Glowing Skin | Collagen Boosting Wrinkle Repair | No Oily Residue...\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import chromadb\n",
    "from config import DATASET_CONFIGS_MPNET\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"\n",
    "    Initialize the MPNet model and tokenizer for generating query embeddings.\n",
    "    This ensures we use the same model as was used for creating the embeddings.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer, device\n",
    "\n",
    "def generate_embedding(text, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a query text using the MPNet model.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, return_dict=True)\n",
    "        embeddings = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "        embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)  # Normalize\n",
    "    \n",
    "    return embeddings.cpu().numpy().tolist()[0]\n",
    "\n",
    "def test_chromadb_collections():\n",
    "    \"\"\"\n",
    "    Test function to check the contents and query functionality of ChromaDB collections.\n",
    "    \"\"\"\n",
    "    # Initialize the model for querying\n",
    "    model, tokenizer, device = initialize_model()\n",
    "    \n",
    "    # Test queries for each dataset\n",
    "    test_queries = {\n",
    "        \"beauty\": [\n",
    "            \"moisturizing face cream for dry skin\",\n",
    "            \"natural organic shampoo\",\n",
    "            \"anti-aging serum with vitamin C\"\n",
    "        ],\n",
    "        \"video_games\": [\n",
    "            \"action adventure game with great story\",\n",
    "            \"multiplayer strategy game\",\n",
    "            \"role playing game with open world\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for dataset, config in DATASET_CONFIGS_MPNET.items():\n",
    "        print(f\"\\n{'='*20} Testing {dataset.upper()} Collection {'='*20}\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize ChromaDB client\n",
    "            client = chromadb.PersistentClient(path=config['db_path'])\n",
    "            collection = client.get_collection(name=config['collection_name'])\n",
    "            \n",
    "            # Print collection info\n",
    "            collection_count = collection.count()\n",
    "            print(f\"\\nTotal items in collection: {collection_count}\")\n",
    "\n",
    "            # Show sample items\n",
    "            if collection_count > 0:\n",
    "                print(\"\\nSample of stored items:\")\n",
    "                sample = collection.peek(limit=2)\n",
    "                for i, (id, metadata, document) in enumerate(zip(\n",
    "                    sample['ids'],\n",
    "                    sample['metadatas'],\n",
    "                    sample['documents']\n",
    "                )):\n",
    "                    print(f\"\\nItem {i + 1}:\")\n",
    "                    print(f\"ID: {id}\")\n",
    "                    print(f\"Metadata: {metadata}\")\n",
    "                    print(f\"Document preview: {document[:150]}...\")\n",
    "\n",
    "                # Perform test queries\n",
    "                print(f\"\\nPerforming test queries for {dataset}:\")\n",
    "                for query in test_queries[dataset]:\n",
    "                    print(f\"\\nQuery: '{query}'\")\n",
    "                    \n",
    "                    # Generate embedding for the query\n",
    "                    query_embedding = generate_embedding(query, model, tokenizer, device)\n",
    "                    \n",
    "                    # Query the collection\n",
    "                    results = collection.query(\n",
    "                        query_embeddings=[query_embedding],\n",
    "                        n_results=3,\n",
    "                        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "                    )\n",
    "                    \n",
    "                    # Display results\n",
    "                    print(\"\\nTop 3 matches:\")\n",
    "                    for i in range(len(results['distances'][0])):\n",
    "                        print(f\"\\nMatch {i+1}:\")\n",
    "                        print(f\"Distance: {results['distances'][0][i]:.4f}\")\n",
    "                        print(f\"Metadata: {results['metadatas'][0][i]}\")\n",
    "                        print(f\"Document preview: {results['documents'][0][i][:150]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error while testing {dataset} collection: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing ChromaDB Collections with MPNet Embeddings and Queries\")\n",
    "    test_chromadb_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
