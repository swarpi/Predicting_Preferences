{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs from first JSON file:\n",
      "[6, 70, 218, 176, 56, 60, 63, 75, 103, 193, 196, 200, 22, 25, 54, 57, 167, 85, 90, 127, 53, 73, 115, 165, 210, 212, 89, 174, 192, 235, 11, 172, 237, 110, 98, 113, 49, 126, 162, 247, 2, 35, 93, 183, 189, 205, 59, 117, 198, 223]\n",
      "\n",
      "User IDs from second JSON file:\n",
      "['AFSKPY37N3C43SOI5IEXEK5JSIYA', 'AHV6QCNBJNSGLATP56JAWJ3C4G2A', 'AFJBKPK5W56XWSNPQU2WW66ISWYQ', 'AFXF3EGQTQDXMRLDWFU7UBFQZB7Q', 'AFWVN52MRBWOTIK7UGXBWGOY4HBA', 'AFQQQ5LGNSQUEBGDCYBAZZE5T3DA', 'AGAM2CCKV52HI4YZU7ASZTSXA7YQ', 'AF2BLE54TEMGZ546U763ZHZRXC4A', 'AGZZXSMMS4WRHHJRBUJZI4FZDHKQ', 'AGD25H7BIT2JUXSIOPYCYB23J3ZQ', 'AEXGISIVX7WBUNI7UHHERVB3DF7Q', 'AEZP6Z2C5AVQDZAJECQYZWQRNG3Q', 'AGTW6ZGPUAORQ7X6CNBP6PJW7OTA', 'AHALZ7AKVAVL7QEVBCI55JVLGXOQ', 'AHTLWVDXSMG5YMVMEIWWOU6XBZMA', 'AHMG3ALUBE3FEBHODTBHP5J24YDA', 'AG73BVBKUOH22USSFJA5ZWL7AKXA', 'AH7LDXK3GT67FZKMRW7MP477DJVQ', 'AE3KLVXGZPANXE5XLXYKHTVAZ3FQ', 'AETWQ4GYGV4QRMTMWGBIDVASBKHA', 'AH6JLX5SJSUOJBBT6RRE2RDXIG6A', 'AF2YKZQRMRGJ655I3MKQUYFGRQGA', 'AHWCZ47A7FIYEJ7KEJG3BO3F5YXQ', 'AF4P6A3SEKS2HCISWAKFZVIFM7NQ', 'AECQQBG6YRYCOJL2NCB2H3V6LD6Q', 'AFVV7CLXY43P3Z3F7SROBZATZVSQ', 'AEXYLV5YOYWSLGG47VVECVURA7XQ', 'AEAXAJACFMXIAAH4WOHRMXPSZWFA', 'AFZDKJMOCGD5KJ2TXWOZB5OAJO5A', 'AH5HSMUMRJRDWBPFDQ6G3EAAOSFQ', 'AHT6AM6BNIZUHFJB5V2M6XM72G7Q', 'AG644AQBRT56BVFDCJMISCNTSRMA', 'AEMRAZPNN2NBBUDV4YGGYMGPFC6A', 'AH2LTMRG3MQNGRZYPPCOJF4KPS3A', 'AH3BXW7KLIS2VAE56UXJS2NS7I5A', 'AEPEDW5FBBJ2XYR2BIJAKUPHCMHA', 'AF3RENOGZJOCO24HPO75EEIF4EHQ', 'AES3YWD3ONJOUDRWFIV2ZO44QDAQ', 'AELHYMCYVS6T35HA3UH5UGFWTK6Q', 'AEYVPPWR4CIKWX4BGYKCBCDL2CZQ', 'AGYVC7KVHP2AWM7BDCEYNHFA6F3Q', 'AGBG3KK74IKWJNQVMQAGVBWJ7FAQ', 'AHX2B4DEER2QR3IU3CCNB3CWC6TA', 'AG4TRGDHYIBT4CH63VJYM5IOAMTQ', 'AEVFWS7JFEKHYDZKH4SI5YDSNGJQ', 'AG3HKK7MIKRQ7DOTNDOE63X2WJGQ', 'AECOPBDL3PHOESNB2RXKPZSXGBOA', 'AGLGCQJ6R7DK2HOZRYGHMQ7D6BTA', 'AGJWAZESYDYURVDSAMHKVAM2IBWQ', 'AFKX24ALWAPX366KX6DWTOBWLQAA', 'AF2LFSDT2SHRD2WEEC3O2ZWIWYEQ', 'AEGKJTQWHGBIOTO34OB3GKIGCN7A', 'AFNRGRORFAGSB7WGANETBDDYDEAQ', 'AEUAQ6BAUEBP2C754LR3ILYHP54Q', 'AHBDPVXHGNIRMIGLCRCABCOLFJTA', 'AF7XNTURXVPO55T5EP4B4DVPQPPQ', 'AEHLKY7Q5O3D3E6YEV67JIBVFNFA', 'AH5ONINJRNZ674DXUMV4RMYIFYVQ', 'AG7JCEMC64AM7JPATDVGP6YZOTXA', 'AGSVNZDZNPCMXG5DEFXMZNRH2LCQ', 'AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ', 'AHGQDSOBAIVAAKJFIVEGS344MSXA', 'AEHWKRPNWNMOAJSMO2F6O7RFRTNA', 'AG7WXYJR3N3IOL7NX6QUZJUPBVDA', 'AE3PLZHW6NXWBMZ76TDVFQG2MJFA', 'AH5PGJYVXBFVRXAFSTA7AEH4EXRQ', 'AF3SRSVEGKHPRSWJ5G4GDUILTOYA', 'AFZGS7XLGLJFUSUWNX4XA6SGEZQA', 'AGRO3UTLKTF724ZW64QXGWXJ4SYA', 'AELRWE7QQJRKDFHDQHVAODTF5FRA', 'AHCR53CDYDQAS6C5TZXQWB4PWTCQ', 'AGFXY5HVXFJFJ2SJDGZL5YLGR6RA', 'AEQJM4TTCTH6MTHXAUQHIZ4JZZHA', 'AGFBEZSOTMPM4M4CHRW3QPDAHJUQ', 'AGCV6N4LVTEQVYSE3LXR3J2QB3EA', 'AGLLAOO4MTOC5RG6EIUCOSK4XXXA', 'AEPKAGO2WGVI55RQAVNBXKGJ2BOQ', 'AF5IQSGLYMWLW4KH2V7VTUZLHUOA', 'AFLI33M7ADMQ2B3DSIJLODWUHTAA', 'AEGTJSI4X2EZHAL5VWJV3RCJIO4A', 'AEH7RAIDBU7QALXTMWAA73PTL4JA', 'AGZYMSCZZ5SPWHX5AVWTP64TY7AA', 'AHH7DYW535JNEGASCET44RLTKG7A', 'AECTRGMRKOGAYIV3YXX73CQEQCSQ', 'AFGCJIO7DNVCCZPG4KVMKKXVPJLQ', 'AGNUU44ETNXLBOUB53LJGFJP3SQA', 'AGWF6BTLJVQQ2N2R5PKNJOLY65GQ', 'AHHWCYE6JF6MMRDKHOGRTNAUOMPA', 'AGADKXWLAJJ4FGWIDIWAPJL5A6HA', 'AHPG65LKS3QKRWDUWAKZNLEK5RZQ', 'AGRKJRPX6I5DQPODOC4YJ7CT4XWA', 'AE3LUVAAITFJIUTWBMRPHDQOCOFQ', 'AFPPNF3RSFMMNC5UAM6V4B475MBQ', 'AFFHB6JLPVY4W566NW67GFKDBRNQ', 'AEPY4UJP6QEKT5DBCY2QYMAFMMAQ', 'AEFU6XKGH6J4ZIYTVVBGEDUCTZHQ', 'AGWXHH2DQWVMVZA3GHAFJQ7ROGQA', 'AGFAOH3NMW2D7YV3QVZSTXMTSKIQ', 'AHC6X7NTYM3C36TZF7C3K3Q7HDEA', 'AECIT3NMW6RKABFS6YOCYX4YUYOQ', 'AGPGFFJDCKXPNBWCC5YP2ZUDPNGA', 'AHMZDG7TLXFO6H5RPWEX6PX6EN5A', 'AF4T3AQXLGSWBXPJV3RI2DBPEYUA', 'AGJMUGA3ZLDJXI7HMYAZXXISE3UQ', 'AFHB5H6XQKOFLV7JRZUBA6IHJC6A', 'AFEYLO2BKJA2CAG6QGE55RGC7PDA', 'AEE4M36AZAKURLEYGV23TM3BE7OQ', 'AF4UB2PGVLHK45WF7I6OED36OQDA', 'AEQ7D7IDDUFNPOL4VDSXWZPIWKUQ', 'AELZIKZNMROP2SMO5XXVB4V36RJA', 'AFESFBY7EYJMQNKR572SZFAAET5Q', 'AF2AJZ2KIDH4QJSOXBKCFGAZITGA', 'AHVS5I6ROMNPROYEMWTCCLR6WP6A', 'AGK5FHPJXPI75CVFCUKFFKLIF3VQ', 'AGNP7WAB6CTY72PMMJZTE2DABPPA', 'AH4PCTM7BHVUX6WCGJB5PNS6K3JQ', 'AFDNVPMB44ZS5O2CSJTL47BI2QTQ', 'AE53TOMIUB7ENP3RD44KDAARU6AQ', 'AHLZVZPQ5TWJ6KXNLADJBDZAT7EA', 'AFEFRMJ5OQHPKVHB3YSZXIS7V4CQ', 'AEK3IYABOEGTXOTX7P6SBQJUP57A', 'AEZG2W4TRMMNFFAWS2BPQE676K4Q', 'AGAVFN7CIWVLIDLJSMFNLJWNEDUQ', 'AHPGHDFIU3BUB3RQBP56RQQA7W4Q', 'AE3UKETTR77J4LM2ZE4AEUC4L6KA', 'AF5A5PMCP3EPIOVGZSAJWNICC6UQ', 'AFPMVI6ZRR7KS7AWRIBCKILWDVIA', 'AHOYQ263ZGBZIBPQGKNVAWG35DNQ', 'AGXMWJK3YL4SV5FJ27JEJZPZHRBA', 'AFB7QGOJXRTRRZ3SDOSIRCR66UQQ', 'AHA6NYC6QHOU7G37PNF5EBIOUBWQ', 'AHSP5IKX6USXFMSHWDQMXSKAEJ3Q', 'AFB3QHU3MOWSWQ7ISC5I7JISKQVQ', 'AFV2E7NCZRG62FXOLQO2SHSN5H3A', 'AHT7TDFPRBZE3GH7RFKCPSCEAR5Q', 'AEPUSQBCPOBYEQDRQD5RI6Q67ERQ', 'AHCA3FF2KQI7SRT32XBZCNHFEHOQ', 'AE3335XF4PMHSXKTW5B7N7EALG3Q', 'AFRUBJ22O26J35OD5MJLBC6RUJKQ', 'AFSQYNVKFMP3WWNXTFTNBFNU3EOA', 'AFSYEOBTC3ULN3DGKABPFR6FIWQQ', 'AGPTRM72WHO5EUPQUWS47FFGAALA', 'AHBWH2LBU3NFLD46GKJKIBAHKXEQ', 'AERJSFYTGI6ACY5VSOYQ5RAN6QFQ', 'AH3POWPCN3JIW3IUL6H24L536NQQ', 'AHXL6HSB4XCGSXWTGDHXNFDAMDDA', 'AECADZLPUNH3BDNACLFF7PSHN5MQ', 'AFR2XB7TRMQJCRB6INYP2W73EH5A', 'AGPCJNECQMG7LPLITZVHXP3F2HUA', 'AH23OXTW7BKRZ3YB6JBQGFB3SMIQ', 'AHY37H4JF643FXWO3USRK3VSFFQA', 'AF4TV3NNARN2N7YV6Z44S2YN237A', 'AEU64BW76A3GKMZAGLUZZORCMB7A', 'AHLQVJPH73V2UVWJCRLAXXFKOGLQ', 'AFNACT4MLU243POBVE666TFVUPGQ', 'AGZSDSHEGWQOJZAJRXGXXV4FULIA', 'AFPQJSBCMEKL3PT54KPROBQ2TAXA', 'AESWZGOSDDULZ2TWG6GLDEU2X5JA', 'AEOK4TQIKGO23SJKZ6PW4FETNNDA_1', 'AHBEKWBIK2I7EPZH4L2Z2G4IZWNA', 'AEHZBUFEOW4TY3K4IYFFR5ZU5B3Q', 'AFGGRGHGHSFKMZASFBYFRHBBEOPA', 'AEKV4Q3JUQTQA2UR7PH7QLUHUTTQ', 'AHY2TURQPNIDXZGH2CMQLZ343YMQ', 'AGN5KJZU3FYSKVWXWM66LXYWL5CQ', 'AESCUI6VXJSHLUIO44Y5ERAHZE4A', 'AFSHXT5PTGDSFW2725SDXIE6ZVEA', 'AHO7CJSLW22GMWPFB35V3L4OFUYQ', 'AFTJ7XQN2EIELHARUBBL6Y7L65DA', 'AFO6QRJE7PPMBY2P66V2FPKJUIEA', 'AERGQ6U7YCR6JZ54FFKYPUM7PFDQ', 'AFKZESU3PTCQ2UVDBDSFVFTXBFNQ_1', 'AGTGHYRTZXKX4AIL42A3FKWR7SOQ', 'AG4D44BNNLUEZNG7COK2CNRYUHYQ', 'AGV5NQ4JDQD6NHXVF6AVZPVDX66Q', 'AH36N5HJJQCBDAURJUTFAIB4GRFA', 'AEV7Q27IHW3CU2NGA5NMHVHTLIAQ', 'AEIW7GMVHQ4HBUXTTYEMHEMADUMQ', 'AEXO6YBJHQZFPLVRQJI6VX7IJDNA', 'AHUIIYUMY5OXQWRECL5JEK4AITBA', 'AEHGY7TZA4IMOXXBGPTZC7UPM6UQ', 'AFZIHXLLRIZYAZDRCGC3Z4DYUMQQ', 'AHG5KKQMMZJA46LDH73IZ4QUHYXA', 'AESIZ3ATHVPMZM5NI6ZJOZBH547A', 'AEQKG4FNUB67X4JUBJRWT3ISVKDQ', 'AG5A4BNLSYHH2IEFJD3UM3N2IPMA', 'AGLQET6T4ZX4C4UXTNEMYHIWLFHA', 'AE5GH4VM5Q5HNUL4EOAYRLNB7RVA', 'AH5BEMAKZE5RJ3JSHUYOJ7S2WKBA', 'AG3FVTSD7ISLKALIPY24IVJCCDTA', 'AENALXICBEUWDJG6U2GYCGEVM3OQ', 'AGQIUTI7M4XUGCRV6E66FAOCX5PQ', 'AGGAEZZTJZWEGLEMKXW5NTNXH7VQ', 'AHGIDR4IJFS23Q4GTZ33FI5LYDSQ_1', 'AEIGRLFPH5Z3EQ73Z23CJ3WX6R6A', 'AEXPTZ272HHG2KO2JAGU5IL45HIQ', 'AHEJQ4CPSHAQNTHL4BCVCAPZ7YWA', 'AEKNMPUXBMNMHDYWMLKOUTEY3LYA', 'AEWHLGO6FWZ4ZO7N6TX7I2FYO6EA', 'AFFGJTTHRCSKGMMCNHT7UWTMKKCQ', 'AHDVSLWHSORYGG3S5QZMVDFNOXUQ', 'AE3QBGRRHKT3GFDPRXFEN7JICEZQ', 'AHTOPAM4UMS6AZRFWMBBXWNYYEVQ', 'AGZUJTI7A3JFKB4FP5JOH6NVAJIQ_1', 'AHPG65LKS3QKRWDUWAKZNLEK5RZQ_1', 'AGLW4RPFGBKWE3FBZBEP2JWUIOCA', 'AGOLMT3QETKYNESRYKBA6D7XXS7A', 'AGQXRXHIEUGJU6KNUPNWMXYBRREA', 'AGC7QCUXJISMEA6RKUGWBKYFA3EA', 'AEODUUL6REW3PW2ZGFREKGWBYUZA', 'AFY3DF5ZXFAWH5ADLZPJYCW2IM2Q', 'AE23ZBUF2YVBQPH2NN6F5XSA3QYQ', 'AEJU3Z6HDAERETMYI2CXBQVPPDFA', 'AEZUL3R34WWAORYARPTJG2X6KC5Q_1', 'AGQVYRFKX6G5VO65RHQ7UZKGSTKQ', 'AEV4UO43YIZXLNB4E64KWRJ3ACXQ', 'AEBWGXGGL3Q5DSTMUQSTVUJDWSMA', 'AGLIUT3VWAE7UEZHWVHNLDTBOAEQ', 'AEC6IZVI2NGFBCIYVD4X5MDGB6DQ_2', 'AHYOSWORVZFXM5QMRIAW3JTTFFIQ', 'AEMP3A7IKW37CMWFXNKXWW6HGJHA_1', 'AHBFC446AIQBMLC3U4SV6YJJERPQ', 'AFBUKVT3KQFLL4X536HS4KKBBJ7Q', 'AEAT2QOOIXWFLBQESCVLAVXLK3RQ', 'AFDYIK3FNPY2JFBQYUWC6GSBMIRQ_2', 'AE5IMGWRBJA7JQFBQTBK25HDYGVA', 'AHF2R43HMV6S2J42LN6NLQTRBLJA', 'AH4TB6XJJKH3WLSX2D56JYJ4Z4ZA', 'AG2V56KGC2Y3VNKPON3W56ZGFOFA', 'AEFRTLVCVRALKXBED77KHPIXEPWQ', 'AE5ESL52LWWBJTSFOAXSFZA3XCGQ', 'AFZSVK7P23M2B7GYUYU7TQIHCGFA_1', 'AFVOZ4UNUZKEQ7GTQ3IHQY7PZ5FA_1', 'AGS4KJHF5LOOWT2A5TJJFMB24VOA', 'AGCGQWDEGSGIIT7AZZ7RGY5ZU74Q', 'AFNCHMAKUAJOGVCKOA4XGLINHPDQ', 'AHSV4TYSAX52BIHH7PLZRD44KZHA', 'AEVFWS7JFEKHYDZKH4SI5YDSNGJQ_1', 'AFJOKSJE3KPYSUXT6TCKRRD4RO2Q', 'AGFLDIUYV2PKF5Q7IEMULR52GW2Q', 'AETJVSLQFY2F7D5AZ7H4ONORPQEQ_1', 'AGV2YW5B3SCKG6WV422CIITZOGRQ', 'AGROTY3KEQXC7OWGNLDMPTDPJXHA', 'AFLKX7ZNVK2DN6LG3EAP6ZNYUFHA', 'AF4XCHGF2AJ4S2MV22Y7KOUJFZPQ', 'AEOJWMWHWXTDHZ2X6TLFNHCOEH4Q', 'AFUWF5DARSSBPDLHSY67Q3LCI54Q', 'AFRMOOG7VG4WSGTOQCQMGLIGC5LA_1', 'AEOTWG667CGEIHYH33COIX53Y25Q', 'AHT556AWAYQIXS3RB57QNRQLBARQ', 'AESI2BA4YODTHOSRFLJCSTAM6XDQ', 'AFKZESU3PTCQ2UVDBDSFVFTXBFNQ_2', 'AG3GU5MHHM662AATYNDWYOKOZP7A']\n",
      "\n",
      "Matched User IDs:\n",
      "6: AFQQQ5LGNSQUEBGDCYBAZZE5T3DA\n",
      "70: AELRWE7QQJRKDFHDQHVAODTF5FRA\n",
      "218: AGLIUT3VWAE7UEZHWVHNLDTBOAEQ\n",
      "176: AH36N5HJJQCBDAURJUTFAIB4GRFA\n",
      "56: AF7XNTURXVPO55T5EP4B4DVPQPPQ\n",
      "60: AGSVNZDZNPCMXG5DEFXMZNRH2LCQ\n",
      "63: AEHWKRPNWNMOAJSMO2F6O7RFRTNA\n",
      "75: AGCV6N4LVTEQVYSE3LXR3J2QB3EA\n",
      "103: AF4T3AQXLGSWBXPJV3RI2DBPEYUA\n",
      "193: AGGAEZZTJZWEGLEMKXW5NTNXH7VQ\n",
      "196: AEXPTZ272HHG2KO2JAGU5IL45HIQ\n",
      "200: AFFGJTTHRCSKGMMCNHT7UWTMKKCQ\n",
      "22: AF2YKZQRMRGJ655I3MKQUYFGRQGA\n",
      "25: AECQQBG6YRYCOJL2NCB2H3V6LD6Q\n",
      "54: AEUAQ6BAUEBP2C754LR3ILYHP54Q\n",
      "57: AEHLKY7Q5O3D3E6YEV67JIBVFNFA\n",
      "167: AFSHXT5PTGDSFW2725SDXIE6ZVEA\n",
      "85: AFGCJIO7DNVCCZPG4KVMKKXVPJLQ\n",
      "90: AHPG65LKS3QKRWDUWAKZNLEK5RZQ\n",
      "127: AFPMVI6ZRR7KS7AWRIBCKILWDVIA\n",
      "53: AFNRGRORFAGSB7WGANETBDDYDEAQ\n",
      "73: AEQJM4TTCTH6MTHXAUQHIZ4JZZHA\n",
      "115: AGNP7WAB6CTY72PMMJZTE2DABPPA\n",
      "165: AGN5KJZU3FYSKVWXWM66LXYWL5CQ\n",
      "210: AEODUUL6REW3PW2ZGFREKGWBYUZA\n",
      "212: AE23ZBUF2YVBQPH2NN6F5XSA3QYQ\n",
      "89: AGADKXWLAJJ4FGWIDIWAPJL5A6HA\n",
      "174: AG4D44BNNLUEZNG7COK2CNRYUHYQ\n",
      "192: AGQIUTI7M4XUGCRV6E66FAOCX5PQ\n",
      "235: AGCGQWDEGSGIIT7AZZ7RGY5ZU74Q\n",
      "11: AEXGISIVX7WBUNI7UHHERVB3DF7Q\n",
      "172: AFKZESU3PTCQ2UVDBDSFVFTXBFNQ_1\n",
      "237: AHSV4TYSAX52BIHH7PLZRD44KZHA\n",
      "110: AELZIKZNMROP2SMO5XXVB4V36RJA\n",
      "98: AGFAOH3NMW2D7YV3QVZSTXMTSKIQ\n",
      "113: AHVS5I6ROMNPROYEMWTCCLR6WP6A\n",
      "49: AGJWAZESYDYURVDSAMHKVAM2IBWQ\n",
      "126: AF5A5PMCP3EPIOVGZSAJWNICC6UQ\n",
      "162: AFGGRGHGHSFKMZASFBYFRHBBEOPA\n",
      "247: AFUWF5DARSSBPDLHSY67Q3LCI54Q\n",
      "2: AHV6QCNBJNSGLATP56JAWJ3C4G2A\n",
      "35: AH3BXW7KLIS2VAE56UXJS2NS7I5A\n",
      "93: AFPPNF3RSFMMNC5UAM6V4B475MBQ\n",
      "183: AHG5KKQMMZJA46LDH73IZ4QUHYXA\n",
      "189: AH5BEMAKZE5RJ3JSHUYOJ7S2WKBA\n",
      "205: AHPG65LKS3QKRWDUWAKZNLEK5RZQ_1\n",
      "59: AG7JCEMC64AM7JPATDVGP6YZOTXA\n",
      "117: AFDNVPMB44ZS5O2CSJTL47BI2QTQ\n",
      "198: AEKNMPUXBMNMHDYWMLKOUTEY3LYA\n",
      "223: AFBUKVT3KQFLL4X536HS4KKBBJ7Q\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File paths for the provided JSON files\n",
    "file1_path = 'qlora_finetuning_dataset_19_11.json'\n",
    "file2_path = r'D:\\Master_Thesis\\final_pipeline\\new_data\\new_train_output.json'  # Use raw string for Windows paths\n",
    "\n",
    "# Read and parse the JSON file to extract UserID from the first file\n",
    "with open(file1_path, 'r') as file1:\n",
    "    json_data1 = json.load(file1)\n",
    "    user_ids_file_1 = []\n",
    "    for entry in json_data1:\n",
    "        for user in entry.get(\"users\", []):\n",
    "            if \"UserID\" in user:\n",
    "                user_ids_file_1.append(int(user[\"UserID\"]))  # Ensure the value is treated as an integer index\n",
    "\n",
    "# Read and parse the JSON file to extract all user IDs from the second file\n",
    "with open(file2_path, 'r') as file2:\n",
    "    json_data2 = json.load(file2)\n",
    "    user_ids_file_2 = [entry[\"user_id\"] for entry in json_data2 if \"user_id\" in entry]\n",
    "\n",
    "# Match User IDs using the first JSON as index for the second JSON\n",
    "matched_ids = {}\n",
    "for user_id_1 in user_ids_file_1:\n",
    "    if 0 <= user_id_1 < len(user_ids_file_2):  # Ensure index is within bounds\n",
    "        matched_ids[user_id_1] = user_ids_file_2[user_id_1-1]\n",
    "\n",
    "# Print the user ids from the first file\n",
    "print(\"User IDs from first JSON file:\")\n",
    "print(user_ids_file_1)\n",
    "\n",
    "# Print the user ids array from the second file\n",
    "print(\"\\nUser IDs from second JSON file:\")\n",
    "print(user_ids_file_2)\n",
    "\n",
    "# Print matched user IDs\n",
    "print(\"\\nMatched User IDs:\")\n",
    "for key, value in matched_ids.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New JSON file with user profiles saved to: new_candidate_items_with_profile.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File paths for the provided JSON files\n",
    "file1_path = 'filtered_data_excluding_description.json'\n",
    "file2_path = r'D:\\Master_Thesis\\final_pipeline\\new_data\\new_train_output.json'\n",
    "output_file_path = 'new_candidate_items_with_profile.json'  # Path for the new JSON file\n",
    "\n",
    "# Read and parse the JSON file to extract UserID from the first file\n",
    "with open(file1_path, 'r') as file1:\n",
    "    json_data1 = json.load(file1)\n",
    "\n",
    "# Read and parse the JSON file to extract all user IDs from the second file\n",
    "with open(file2_path, 'r') as file2:\n",
    "    json_data2 = json.load(file2)\n",
    "    user_ids_file_2 = [entry[\"user_id\"] for entry in json_data2 if \"user_id\" in entry]\n",
    "\n",
    "# Create the new JSON structure\n",
    "new_json_data = []\n",
    "\n",
    "for entry in json_data1:\n",
    "    for user in entry.get(\"users\", []):\n",
    "        user_id_index = int(user[\"UserID\"])  # Get the UserID as an integer\n",
    "        if 1 <= user_id_index <= len(user_ids_file_2):  # Check index bounds (adjusted for 1-based index)\n",
    "            user_asin = user_ids_file_2[user_id_index - 1]  # Adjust for 0-based indexing\n",
    "            extracted_products = eval(user.get(\"Extracted Products\", \"[]\"))  # Convert string to list\n",
    "            candidate_items = {str(i + 1): product for i, product in enumerate(extracted_products)}\n",
    "            \n",
    "            # Construct User_Profile\n",
    "            short_term = user.get(\"Profile Sections\", {}).get(\"Short-Term Interests\", \"\")\n",
    "            long_term = user.get(\"Profile Sections\", {}).get(\"Long-term Preferences\", \"\")\n",
    "            profile_summary = user.get(\"Profile Sections\", {}).get(\"User Profile Summary\", \"\")\n",
    "            user_profile = (\n",
    "                f\"\\\"Short-Term Interests\\\": {short_term}\\n\"\n",
    "                f\"\\\"Long-Term Preferences\\\": {long_term}\\n\"\n",
    "                f\"\\\"User_Profile\\\": {profile_summary}\"\n",
    "            )\n",
    "            \n",
    "            # Construct the new JSON entry\n",
    "            new_entry = {\n",
    "                \"User_ID\": user_asin,\n",
    "                \"User_Profile\": user_profile,\n",
    "                \"Candidate_Items\": candidate_items\n",
    "            }\n",
    "            \n",
    "            new_json_data.append(new_entry)\n",
    "\n",
    "# Write the new JSON data to a file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(new_json_data, output_file, indent=4)\n",
    "\n",
    "print(f\"New JSON file with user profiles saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted UserIDs: [2, 6, 11, 22, 25, 35, 49, 53, 54, 56, 57, 59, 60, 63, 70, 73, 75, 85, 89, 90, 93, 98, 103, 110, 113, 115, 117, 126, 127, 162, 165, 167, 172, 174, 176, 183, 189, 192, 193, 196, 198, 200, 205, 210, 212, 218, 223, 235, 237, 247]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def print_sorted_user_ids(json_file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file and prints all the UserIDs in sorted order.\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): Path to the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Collect all UserIDs\n",
    "        user_ids = []\n",
    "        for entry in data:\n",
    "            for user in entry.get(\"users\", []):\n",
    "                user_ids.append(int(user[\"UserID\"]))  # Convert to int for sorting\n",
    "\n",
    "        # Sort and print UserIDs\n",
    "        user_ids.sort()\n",
    "        print(\"Sorted UserIDs:\", user_ids)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# Example usage\n",
    "json_file_path = \"qlora_finetuning_dataset_19_11_with_id.json\"\n",
    "print_sorted_user_ids(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate user_ids found.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def check_duplicate_user_ids_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file and checks for duplicate user_ids.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the JSON file.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of duplicate user_ids, or an empty list if no duplicates are found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        \n",
    "        # Extract user_ids and check for duplicates\n",
    "        user_ids = [entry['User_ID'] for entry in json_data]\n",
    "        duplicates = [user_id for user_id in set(user_ids) if user_ids.count(user_id) > 1]\n",
    "        return duplicates\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON format in file: {file_path}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "file_path = 'new_candidate_items_with_profile.json'  # Replace with the path to your JSON file\n",
    "duplicates = check_duplicate_user_ids_from_file(file_path)\n",
    "if duplicates:\n",
    "    print(\"Duplicate user_ids found:\", duplicates)\n",
    "else:\n",
    "    print(\"No duplicate user_ids found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Original main source length: 46\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEXGISIVX7WBUNI7UHHERVB3DF7Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEUAQ6BAUEBP2C754LR3ILYHP54Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AFGGRGHGHSFKMZASFBYFRHBBEOPA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEKNMPUXBMNMHDYWMLKOUTEY3LYA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AFFGJTTHRCSKGMMCNHT7UWTMKKCQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHSV4TYSAX52BIHH7PLZRD44KZHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEXGISIVX7WBUNI7UHHERVB3DF7Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AETWQ4GYGV4QRMTMWGBIDVASBKHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHWCZ47A7FIYEJ7KEJG3BO3F5YXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGCV6N4LVTEQVYSE3LXR3J2QB3EA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF5A5PMCP3EPIOVGZSAJWNICC6UQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AFGGRGHGHSFKMZASFBYFRHBBEOPA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AFJBKPK5W56XWSNPQU2WW66ISWYQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AETWQ4GYGV4QRMTMWGBIDVASBKHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEUAQ6BAUEBP2C754LR3ILYHP54Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEOK4TQIKGO23SJKZ6PW4FETNNDA_1\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGV5NQ4JDQD6NHXVF6AVZPVDX66Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEXGISIVX7WBUNI7UHHERVB3DF7Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AETWQ4GYGV4QRMTMWGBIDVASBKHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHWCZ47A7FIYEJ7KEJG3BO3F5YXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEUAQ6BAUEBP2C754LR3ILYHP54Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF3SRSVEGKHPRSWJ5G4GDUILTOYA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEOK4TQIKGO23SJKZ6PW4FETNNDA_1\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHBEKWBIK2I7EPZH4L2Z2G4IZWNA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEXPTZ272HHG2KO2JAGU5IL45HIQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEKNMPUXBMNMHDYWMLKOUTEY3LYA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHSV4TYSAX52BIHH7PLZRD44KZHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEXGISIVX7WBUNI7UHHERVB3DF7Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AETWQ4GYGV4QRMTMWGBIDVASBKHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AFKX24ALWAPX366KX6DWTOBWLQAA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AG7WXYJR3N3IOL7NX6QUZJUPBVDA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF3SRSVEGKHPRSWJ5G4GDUILTOYA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHH7DYW535JNEGASCET44RLTKG7A\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEOK4TQIKGO23SJKZ6PW4FETNNDA_1\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGV5NQ4JDQD6NHXVF6AVZPVDX66Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AETWQ4GYGV4QRMTMWGBIDVASBKHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHWCZ47A7FIYEJ7KEJG3BO3F5YXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AH5ONINJRNZ674DXUMV4RMYIFYVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF3SRSVEGKHPRSWJ5G4GDUILTOYA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGCV6N4LVTEQVYSE3LXR3J2QB3EA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEOK4TQIKGO23SJKZ6PW4FETNNDA_1\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHBEKWBIK2I7EPZH4L2Z2G4IZWNA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AETWQ4GYGV4QRMTMWGBIDVASBKHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHWCZ47A7FIYEJ7KEJG3BO3F5YXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEAXAJACFMXIAAH4WOHRMXPSZWFA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEUAQ6BAUEBP2C754LR3ILYHP54Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF5A5PMCP3EPIOVGZSAJWNICC6UQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AH3POWPCN3JIW3IUL6H24L536NQQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHBEKWBIK2I7EPZH4L2Z2G4IZWNA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHSV4TYSAX52BIHH7PLZRD44KZHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AETWQ4GYGV4QRMTMWGBIDVASBKHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHWCZ47A7FIYEJ7KEJG3BO3F5YXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEUAQ6BAUEBP2C754LR3ILYHP54Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AH5ONINJRNZ674DXUMV4RMYIFYVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEXGISIVX7WBUNI7UHHERVB3DF7Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEUAQ6BAUEBP2C754LR3ILYHP54Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AH5ONINJRNZ674DXUMV4RMYIFYVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF3SRSVEGKHPRSWJ5G4GDUILTOYA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHBEKWBIK2I7EPZH4L2Z2G4IZWNA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AFGGRGHGHSFKMZASFBYFRHBBEOPA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AETWQ4GYGV4QRMTMWGBIDVASBKHA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEAXAJACFMXIAAH4WOHRMXPSZWFA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEUAQ6BAUEBP2C754LR3ILYHP54Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF3SRSVEGKHPRSWJ5G4GDUILTOYA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHBEKWBIK2I7EPZH4L2Z2G4IZWNA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AFGGRGHGHSFKMZASFBYFRHBBEOPA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEXGISIVX7WBUNI7UHHERVB3DF7Q\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHWCZ47A7FIYEJ7KEJG3BO3F5YXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF3SRSVEGKHPRSWJ5G4GDUILTOYA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AGFXY5HVXFJFJ2SJDGZL5YLGR6RA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AEH7RAIDBU7QALXTMWAA73PTL4JA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHH7DYW535JNEGASCET44RLTKG7A\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AF5A5PMCP3EPIOVGZSAJWNICC6UQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AFGGRGHGHSFKMZASFBYFRHBBEOPA\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHY2TURQPNIDXZGH2CMQLZ343YMQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHTOPAM4UMS6AZRFWMBBXWNYYEVQ\n",
      "[DEBUG] Duplicate user found. Skipping User_ID: AHSV4TYSAX52BIHH7PLZRD44KZHA\n",
      "[DEBUG] Newly added user IDs: ['AHALZ7AKVAVL7QEVBCI55JVLGXOQ', 'AETWQ4GYGV4QRMTMWGBIDVASBKHA', 'AHWCZ47A7FIYEJ7KEJG3BO3F5YXQ', 'AF4P6A3SEKS2HCISWAKFZVIFM7NQ', 'AEAXAJACFMXIAAH4WOHRMXPSZWFA', 'AFKX24ALWAPX366KX6DWTOBWLQAA', 'AEZY3WQ5CO4DOXRNJOWWXJYKCAXQ', 'AF3SRSVEGKHPRSWJ5G4GDUILTOYA', 'AGFXY5HVXFJFJ2SJDGZL5YLGR6RA', 'AF5A5PMCP3EPIOVGZSAJWNICC6UQ', 'AFB7QGOJXRTRRZ3SDOSIRCR66UQQ', 'AH3POWPCN3JIW3IUL6H24L536NQQ', 'AFNACT4MLU243POBVE666TFVUPGQ', 'AHTOPAM4UMS6AZRFWMBBXWNYYEVQ', 'AFJBKPK5W56XWSNPQU2WW66ISWYQ', 'AEH7RAIDBU7QALXTMWAA73PTL4JA', 'AHH7DYW535JNEGASCET44RLTKG7A', 'AFEFRMJ5OQHPKVHB3YSZXIS7V4CQ', 'AEOK4TQIKGO23SJKZ6PW4FETNNDA_1', 'AGV5NQ4JDQD6NHXVF6AVZPVDX66Q', 'AH5ONINJRNZ674DXUMV4RMYIFYVQ', 'AHBEKWBIK2I7EPZH4L2Z2G4IZWNA', 'AG5A4BNLSYHH2IEFJD3UM3N2IPMA', 'AG7WXYJR3N3IOL7NX6QUZJUPBVDA', 'AECIT3NMW6RKABFS6YOCYX4YUYOQ', 'AHO7CJSLW22GMWPFB35V3L4OFUYQ', 'AENALXICBEUWDJG6U2GYCGEVM3OQ', 'AHY2TURQPNIDXZGH2CMQLZ343YMQ', 'AH5PGJYVXBFVRXAFSTA7AEH4EXRQ', 'AHHWCYE6JF6MMRDKHOGRTNAUOMPA', 'AE3PLZHW6NXWBMZ76TDVFQG2MJFA']\n",
      "[DEBUG] Number of newly added users: 31\n",
      "[DEBUG] Updated main source length: 77\n",
      "[DEBUG] Updated main source written to: D:\\Master_Thesis\\final_pipeline\\QLoRa_finetuning\\updated_matching_ids_pipeline.json\n",
      "[DEBUG] Structure is correct for all entries in the updated file.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def analyze_json_files_with_mapping(\n",
    "    main_source_path: str,\n",
    "    runs_paths: list,\n",
    "    user_mapping_path: str,\n",
    "    output_path: str = \"updated_matching_ids_pipeline.json\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyzes the main source JSON (matching_ids_pipeline.json) and a list of\n",
    "    'results' JSON files (_run_1, _run_2, etc.) using a user mapping file\n",
    "    (user_mapping_beauty.json). For each user with Recall@10 > 0:\n",
    "\n",
    "      1. Convert the numeric user_id (from the results JSON) to the real user ID \n",
    "         using user_mapping_beauty.json.\n",
    "      2. Check whether the real user ID already exists in the main source.\n",
    "      3. If not, add that new user entry (profile + candidate items) to the main source \n",
    "         in the same schema.\n",
    "\n",
    "    Finally:\n",
    "      - Writes the updated main source to a new JSON file.\n",
    "      - Reads that new file back and checks the structure to ensure correctness.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------\n",
    "    # 1. Load the main source\n",
    "    # -------------------\n",
    "    with open(main_source_path, 'r', encoding='utf-8') as f:\n",
    "        main_source = json.load(f)\n",
    "\n",
    "    original_length = len(main_source)\n",
    "    print(f\"[DEBUG] Original main source length: {original_length}\")\n",
    "\n",
    "    # Convert main_source to a dict {User_ID -> user_object} for quick membership checking\n",
    "    main_source_dict = {user[\"User_ID\"]: user for user in main_source}\n",
    "\n",
    "    # -------------------\n",
    "    # 2. Load and invert user_mapping_beauty.json\n",
    "    # -------------------\n",
    "    with open(user_mapping_path, 'r', encoding='utf-8') as f:\n",
    "        mapping_dict = json.load(f)\n",
    "    # e.g., { \"AFQQQ5LGNSQUEBGDCYBAZZE5T3DA\": 6, ... }\n",
    "    # We want to invert to get { 6: \"AFQQQ5LGNSQUEBGDCYBAZZE5T3DA\", ... }\n",
    "    inverted_mapping = {v: k for k, v in mapping_dict.items()}\n",
    "\n",
    "    # Keep track of newly added users for debug output\n",
    "    newly_added_user_ids = []\n",
    "\n",
    "    # -------------------\n",
    "    # 3. Process each results file (_run_X)\n",
    "    # -------------------\n",
    "    for run_path in runs_paths:\n",
    "        if not os.path.exists(run_path):\n",
    "            print(f\"[DEBUG] Warning: File not found: {run_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(run_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        results = data.get(\"results\", [])\n",
    "\n",
    "        # 4. Check each user in 'results'\n",
    "        for user_data in results:\n",
    "            evaluation = user_data.get(\"evaluation\", {})\n",
    "            recalls = evaluation.get(\"recalls\", {})\n",
    "            recall_at_10 = recalls.get(\"Recall@10\", 0.0)\n",
    "\n",
    "            # If recall_at_10 > 0, that indicates a match\n",
    "            if recall_at_10 > 0:\n",
    "                numeric_user_id = user_data.get(\"user_id\")\n",
    "                try:\n",
    "                    numeric_user_id = int(numeric_user_id)\n",
    "                except (TypeError, ValueError):\n",
    "                    print(f\"[DEBUG] user_id '{numeric_user_id}' is invalid. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Look up real_user_id from the inverted mapping\n",
    "                real_user_id = inverted_mapping.get(numeric_user_id)\n",
    "                if not real_user_id:\n",
    "                    print(f\"[DEBUG] numeric user_id={numeric_user_id} not in mapping. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # If the user_id is already in main_source_dict, skip\n",
    "                if real_user_id in main_source_dict:\n",
    "                    print(f\"[DEBUG] Duplicate user found. Skipping User_ID: {real_user_id}\")\n",
    "                else:\n",
    "                    # Create a new user entry\n",
    "                    new_user = {\n",
    "                        \"User_ID\": real_user_id,\n",
    "                        \"User_Profile\": user_data.get(\"profile\", \"\"),\n",
    "                        \"Candidate_Items\": {}\n",
    "                    }\n",
    "                    # Convert extracted_products to Candidate_Items\n",
    "                    extracted_products = user_data.get(\"extracted_products\", [])\n",
    "                    for i, product in enumerate(extracted_products, start=1):\n",
    "                        new_user[\"Candidate_Items\"][str(i)] = product\n",
    "\n",
    "                    main_source_dict[real_user_id] = new_user\n",
    "                    newly_added_user_ids.append(real_user_id)\n",
    "\n",
    "    # -------------------\n",
    "    # 5. Re-convert to list, write to JSON\n",
    "    # -------------------\n",
    "    updated_main_source = list(main_source_dict.values())\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(updated_main_source, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Debug info\n",
    "    print(f\"[DEBUG] Newly added user IDs: {newly_added_user_ids}\")\n",
    "    print(f\"[DEBUG] Number of newly added users: {len(newly_added_user_ids)}\")\n",
    "    print(f\"[DEBUG] Updated main source length: {len(updated_main_source)}\")\n",
    "    print(f\"[DEBUG] Updated main source written to: {output_path}\")\n",
    "\n",
    "    # -------------------\n",
    "    # 6. Read the new file and check structure\n",
    "    # -------------------\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            final_data = json.load(f)\n",
    "\n",
    "        # Validate each entry’s structure\n",
    "        # Ensure each item is a dict with keys: User_ID, User_Profile, Candidate_Items\n",
    "        correct_structure = True\n",
    "        for idx, entry in enumerate(final_data):\n",
    "            if not isinstance(entry, dict):\n",
    "                print(f\"[ERROR] Entry at index {idx} is not a dict.\")\n",
    "                correct_structure = False\n",
    "                break\n",
    "\n",
    "            required_keys = {\"User_ID\", \"User_Profile\", \"Candidate_Items\"}\n",
    "            if not required_keys.issubset(entry.keys()):\n",
    "                print(f\"[ERROR] Entry at index {idx} does not have the required keys {required_keys}.\")\n",
    "                correct_structure = False\n",
    "                break\n",
    "\n",
    "            if not isinstance(entry[\"Candidate_Items\"], dict):\n",
    "                print(f\"[ERROR] 'Candidate_Items' at index {idx} is not a dict.\")\n",
    "                correct_structure = False\n",
    "                break\n",
    "\n",
    "        if correct_structure:\n",
    "            print(\"[DEBUG] Structure is correct for all entries in the updated file.\")\n",
    "        else:\n",
    "            print(\"[DEBUG] Structure problems were found. Please check the error messages above.\")\n",
    "    else:\n",
    "        print(f\"[DEBUG] Could not verify structure because {output_path} was not found.\")\n",
    "\n",
    "    # Return the updated list in memory, in case you need it\n",
    "    return updated_main_source\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Example Usage\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example paths\n",
    "    main_path = r\"matching_ids_pipeline.json\"\n",
    "    user_mapping_path = r\"user_mapping_beauty.json\"\n",
    "\n",
    "    runs = [\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_full_review\\results_beauty_without_description_no_adapter_reviews_10_sample_None_2024-12-28_run_1_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_full_review\\results_beauty_without_description_no_adapter_reviews_10_sample_None_2024-12-28_run_2_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_full_review\\results_beauty_without_description_no_adapter_reviews_10_sample_None_2024-12-28_run_3_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_full_review\\results_beauty_without_description_no_adapter_reviews_10_sample_None_2024-12-28_run_4_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_full_review\\results_beauty_without_description_no_adapter_reviews_10_sample_None_2024-12-28_run_5_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_beauty_with_description_no_adapter_reviews_10_sample_None_2025-01-07_run_1_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_beauty_with_description_no_adapter_reviews_10_sample_None_2025-01-07_run_2_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_beauty_with_description_no_adapter_reviews_10_sample_None_2025-01-07_run_3_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_beauty_without_description_no_adapter_reviews_100_sample_None_2025-01-08_run_1_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_beauty_without_description_no_adapter_reviews_100_sample_None_2025-01-08_run_2_with_full_reviews.json\",\n",
    "        r\"D:\\Master_Thesis\\final_pipeline\\results_beauty_without_description_no_adapter_reviews_100_sample_None_2025-01-08_run_3_with_full_reviews.json\"\n",
    "    ]\n",
    "    output_file = r\"D:\\Master_Thesis\\final_pipeline\\QLoRa_finetuning\\updated_matching_ids_pipeline.json\"\n",
    "\n",
    "    updated_source = analyze_json_files_with_mapping(\n",
    "        main_source_path=main_path,\n",
    "        runs_paths=runs,\n",
    "        user_mapping_path=user_mapping_path,\n",
    "        output_path=output_file\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
